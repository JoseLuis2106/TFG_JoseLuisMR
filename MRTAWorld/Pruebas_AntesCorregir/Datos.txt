Características de las distintas versiones (3 tareas, 2 robots, tarea completada automáticamente cuando su robot llega a ella).

Nota: La media de recompensas de la prueba no tiene por qué ser representativa (solo son 10 épocas). Sin embargo, puede dar una idea de cómo de bien actúa cada versión (además de observar su comportamiento en simulación). 
Nota: Me he dado cuenta de que el bin del tiempo transcurrido no estaba bien configurado.
Nota: Tambien acabo de ver que el entorno no estaba modificando nunca la variable de estado "task_allocations", y dado que algunas variantes estaban actuando bien (las que tenian menos estados), se ha considerado eliminarla. Si se solucionara esto, aumentaria el numero de estados. Si se decide eliminarla,, habria que reentrenar los algoritmos (los estados almacenados ya no serian validos)
Nota: Posibles errores al calcular número máximo de estados.


1. Version normal/inicial: 
Media recompensas prueba: 126.7
No se almacena el resultado (demasiado grande/demasiados estados?)
Según lo visto, no parece que la red termine de aprender (en algunos episodios, hay steps en los que no asigna tareas o solo asigna 1 en vez de 2).
Nº máximo estados (sin tasks_allocations): ~2.5*10^11

2. Sin el tiempo en los estados:
Media recompensas prueba: 108.6
No se almacena el resultado (idem)
Según lo visto, no parece que la red termine de aprender (idem).
Nº máximo estados (sin tasks_allocations): ~2.5*10^10

3. Distancias en lugar de posiciones:
Media recompensas prueba: 152.4
Se almacena el resultado.
Parece que asigna las tareas de forma bastante eficiente.
Nº máximo estados (sin tasks_allocations): ~1.1*10^6

4. No reasignar tareas ya asignadas sin completar:
Media recompensas prueba: 123.8
No se almacena el resultado (idem)
Según lo visto, no parece que la red termine de aprender (idem).
Nº máximo estados (sin tasks_allocations): ~5.9*10^11

2 y 3:
Media recompensas prueba: 154.5
Se almacena el resultado.
Parece que asigna las tareas de forma bastante eficiente.
Nº máximo estados (sin tasks_allocations): ~1.1*10^5

2 y 4:
Media recompensas prueba: 98.9
No se almacena el resultado.
Comportamiento sil¡milar a 1 y 2.
Nº máximo estados (sin tasks_allocations): ~5.9*10^10

3 y 4:
Media recompensas prueba: 153.8
Se almacena el resultado.
Parece que asigna las tareas de forma bastante eficiente.
Nº máximo estados (sin tasks_allocations): ~2.6*10^6

2, 3 y 4:
Media recompensas prueba: 152.9
Se almacena el resultado.
Parece que asigna las tareas de forma bastante eficiente.
Nº máximo estados (sin tasks_allocations): ~2.6*10^5